{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System\n",
    "### Collaborative filtering using Matrix Factorization for implicit feedback data using simple SVD largest k Singular values.\n",
    "The matrix factorization performed in this notebook Computes the largest k singular values/vectors for a sparse matrix. Based upon the Largest K singular Values we find top K Recommended item. We are using scipy.sparse.linalg library which implements SVD using ARPACK as an eigensolver on A.H * A or A * A.H, depending on which one is more efficient.\n",
    "Note: Datafiles are built from scratch in this notebook only if they don't exist on disk. However, to force rebuild any datafile, there will be a REBUILD_* constant in the respective cell that should be set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as linalg\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from numpy import bincount, log, sqrt\n",
    "import itertools\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting paths for data files\n",
    "base_path=\"../data/\"\n",
    "product_user_matrix_path=base_path+\"product_user_matrix.npz\"\n",
    "order_products_prior_path=base_path+\"../data/order_products__prior.csv\"\n",
    "order_products_train_path=base_path+\"../data/order_products__train.csv\"\n",
    "orders_path=base_path+\"../data/orders.csv\"\n",
    "products_path=base_path+\"../data/products.csv\"\n",
    "test_data_path = base_path+'user_products__test.csv'\n",
    "matrix_df_path = base_path+\"user_products__prior.csv\"\n",
    "matrix_path = base_path+\"product_user_matrix.npz\"\n",
    "product_factor_50_path= base_path+\"product_factor_50.npy\"\n",
    "user_factor_50_path= base_path+\"user_factor_50.npy\"\n",
    "product_factor_100_path= base_path+\"product_factor_100.npy\"\n",
    "user_factor_100_path= base_path+\"user_factor_100.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order & User Datasets\n",
    "df_order_products_prior = pd.read_csv(order_products_prior_path)\n",
    "df_order_products_train = pd.read_csv(order_products_train_path)\n",
    "df_orders = pd.read_csv(orders_path) \n",
    "\n",
    "# Products\n",
    "df_products = pd.read_csv(products_path)\n",
    "\n",
    "# No. of items to recommend\n",
    "rec_items = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test data ...\n",
      "   order_id  user_id\n",
      "0         1        1\n",
      "1        13        3\n",
      "2        26        5\n",
      "3        36        6\n",
      "4        44        7\n",
      "   order_id products\n",
      "0         1      [1]\n",
      "1        13      [9]\n",
      "2        26     [20]\n",
      "3        36     [26]\n",
      "4        44     [35]\n",
      "Completed in 2.81s\n"
     ]
    }
   ],
   "source": [
    "def make_test_data(filepath, df_orders, df_order_products_train):\n",
    "    \"\"\"\n",
    "    Generates the test dataset and saves it to disk at the given path\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Creating test data ...\")\n",
    "\n",
    "    # Read train csv\n",
    "    df_order_user_current = df_orders.loc[(df_orders.eval_set == \"train\")].reset_index()\n",
    "    df_order_user_current = df_order_user_current[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    print(df_order_user_current.head())\n",
    "    \n",
    "    # Sanity check #1: `current_order_user_df` and `df_order_products_train` should have the same number of \n",
    "    # unique order ids\n",
    "    assert len(df_order_user_current[\"order_id\"].unique()) == len(df_order_products_train[\"order_id\"].unique())\n",
    "\n",
    "    # Convert train dataframe to a similar format\n",
    "    df_order_products_test = df_order_products_train[[\"order_id\", \"product_id\"]]\n",
    "    df_order_products_test = df_order_products_test.groupby(\"order_id\")[\"product_id\"].apply(list).reset_index().rename(columns={\"product_id\": \"products\"})\n",
    "    print(df_order_products_test.head())\n",
    "        \n",
    "    # Sanity check #2: `df_order_products_test` and `df_order_user_current` should have the same number of \n",
    "    # records before attempting to merge them\n",
    "    assert df_order_products_test.size == df_order_user_current.size\n",
    "\n",
    "    # Merge on order id\n",
    "    df_user_products_test = pd.merge(df_order_user_current, df_order_products_test, on=\"order_id\")\n",
    "    df_user_products_test = df_user_products_test[[\"user_id\", \"products\"]]\n",
    "\n",
    "    # Write to disk\n",
    "    df_user_products_test.to_csv(filepath, index_label=False, index=False)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "\n",
    "# Generate test data if it doesn't exist already\n",
    "REBUILD_TEST_DATA = True\n",
    "if REBUILD_TEST_DATA or not Path(test_data_path).is_file():\n",
    "    make_test_data(test_data_path, df_orders, df_order_products_train)\n",
    "\n",
    "df_user_products_test = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Dataframe for user-products-quantity for order_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating prior user product data frame ...\n",
      "Completed in 2.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>137756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>152486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id product_id  quantity\n",
       "0       1          2         1\n",
       "1       1          3         1\n",
       "2       1     137756         1\n",
       "3       1     152486         1\n",
       "4       2          5         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_user_product_prior_df(filepath, df_orders, df_order_products_prior):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates a dataframe of users and their prior products purchases, and writes it to disk at the given path\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Creating prior user product data frame ...\")\n",
    "\n",
    "    # Consider ony \"prior\" orders and remove all columns except `user_id` from `df_orders`\n",
    "    df_order_user_prior = df_orders.loc[df_orders.eval_set == \"prior\"]\n",
    "    df_order_user_prior = df_order_user_prior[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    # Remove all columns except order_id and user_id from df_orders and \n",
    "    # merge the above on `order_id` and remove `order_id`\n",
    "    df_merged = pd.merge(df_order_user_prior, df_order_products_prior[[\"order_id\", \"product_id\"]], on=\"order_id\")\n",
    "    df_user_product_prior = df_merged[[\"user_id\", \"product_id\"]]\n",
    "    df_user_product_prior = df_user_product_prior.groupby([\"user_id\", \"product_id\"]).size().reset_index().rename(columns={0:\"quantity\"})\n",
    "    \n",
    "    # Write to disk\n",
    "    df_user_product_prior.to_csv(filepath, index_label=False, index=False)\n",
    "\n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "\n",
    "# Build dataframe of users, products and quantity bought using prior datasets\n",
    "REBUILD_MATRIX_DF = True\n",
    "if REBUILD_MATRIX_DF or not Path(matrix_df_path).is_file():\n",
    "    get_user_product_prior_df(matrix_df_path, df_orders, df_order_products_prior)\n",
    "df_user_product_prior = pd.read_csv(matrix_df_path)\n",
    "# Making them as category for making dictonary of user and item ids later for easy \n",
    "# mapping from sparse Matrix representation\n",
    "df_user_product_prior[\"user_id\"] = df_user_product_prior[\"user_id\"].astype(\"category\")\n",
    "df_user_product_prior[\"product_id\"] = df_user_product_prior[\"product_id\"].astype(\"category\")\n",
    "df_user_product_prior.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_product_user_matrix(matrix_path, df_user_product_prior):\n",
    "    \"\"\"\n",
    "    Generates a utility matrix representing purchase history of users, and writes it to disk.\n",
    "    Rows and Columns represent products and users respectively.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"Creating product user matrix ...\")\n",
    "\n",
    "    product_user_matrix = sparse.coo_matrix((df_user_product_prior[\"quantity\"],\n",
    "                                            (df_user_product_prior[\"product_id\"].cat.codes.copy(),\n",
    "                                             df_user_product_prior[\"user_id\"].cat.codes.copy())))    \n",
    "    sparse.save_npz(matrix_path, product_user_matrix)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating product user matrix ...\n",
      "Completed in 0.26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<142481x45184 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 286402 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build dataframe of users, products and quantity bought using prior datasets\n",
    "REBUILD_USER_MATRIX_DF = True\n",
    "if REBUILD_USER_MATRIX_DF or not Path(matrix_path).is_file():\n",
    "    build_product_user_matrix(matrix_path, df_user_product_prior)    \n",
    "product_user_matrix=sparse.load_npz(product_user_matrix_path).tocsr().astype(np.float32)\n",
    "\n",
    "product_user_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparsity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.99555128671498"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# How sparse is the utility matrix?\n",
    "def sparsity(matrix):\n",
    "    total_size = matrix.shape[0] * matrix.shape[1]\n",
    "    actual_size = matrix.size\n",
    "    sparsity = (1 - (actual_size / total_size)) * 100\n",
    "    return(sparsity)\n",
    "\n",
    "sparsity(product_user_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating User and product factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factors= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_factors_50,user_factors_50 here denote 50 latent Factors considered\n",
    "REBUILD_FACTORS= True\n",
    "if REBUILD_FACTORS or not ((Path(product_factor_50_path)).is_file() \n",
    "                           and (Path(user_factor_50_path)).is_file()): \n",
    "    #Calculating the product and user factors\n",
    "    product_factors_50, S, user_factors_50 = linalg.svds(product_user_matrix, 50)\n",
    "    # changing to user* factor format\n",
    "    user_factors_50=user_factors_50.T*S\n",
    "    # saving the user and product factors\n",
    "    np.save(product_factor_50_path, product_factors_50)\n",
    "    np.save(user_factor_50_path, user_factors_50)\n",
    "else:\n",
    "    # Loading the user and product factors \n",
    "    product_factors_50=np.load(product_factor_50_path)\n",
    "    user_factors_50=np.load(user_factor_50_path)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factors= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_factors_100,user_factors_100 here denotes 100 latent Factors considered\n",
    "REBUILD_FACTORS= True\n",
    "if REBUILD_FACTORS or not ((Path(product_factor_100_path)).is_file() \n",
    "                           and (Path(user_factor_100_path)).is_file()): \n",
    "    #Calculating the product and user factors\n",
    "    product_factors_100, S, user_factors_100 = linalg.svds(product_user_matrix, 100)\n",
    "    # changing to user* factor format\n",
    "    user_factors_100=user_factors_100.T*S\n",
    "    # saving the user and product factors\n",
    "    np.save(product_factor_100_path, product_factors_100)\n",
    "    np.save(user_factor_100_path, user_factors_100)\n",
    "else:\n",
    "    # Loading the user and product factors \n",
    "    product_factors_100=np.load(product_factor_100_path)\n",
    "    user_factors_100=np.load(user_factor_100_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class To find the top recommended items given a user_id\n",
    "class TopRecommended(object):\n",
    "    def __init__(self, product_factors,user_factors,product_user_matrix):\n",
    "        self.product_factors =product_factors\n",
    "        self.user_factors =user_factors\n",
    "        self.product_user_matrix=product_user_matrix\n",
    "    def recommend(self, user_id, N=rec_items):\n",
    "        \n",
    "        \"\"\"\n",
    "        Finds top K Recommendations\n",
    "        \"\"\"\n",
    "        scores =  self.user_factors[user_id].dot(self.product_factors.T)\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        return sorted(zip(best, scores[best]), key=lambda x: -x[1])\n",
    "\n",
    "    def recommend_new(self, user_id, N=rec_items):\n",
    "        \"\"\"\n",
    "        Finds Top k new Recommendations\n",
    "        \"\"\"\n",
    "        scores =  self.user_factors[user_id].dot(self.product_factors.T)\n",
    "        bought_indices=product_user_matrix.T[user_id].nonzero()[1]\n",
    "        count = N + len(bought_indices)\n",
    "        ids = np.argpartition(scores, -count)[-count:]\n",
    "        best = sorted(zip(ids, scores[ids]), key=lambda x: -x[1])        \n",
    "        return list(itertools.islice((rec for rec in best if rec[0] not in bought_indices), N))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictonary to map User_id & Product_id in Utility Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the utility matrix is 0-indexed, the below dict is required to convert between `ids` and `indices`.\n",
    "# For example, `product_id` 1 in the dataset is represented by the `0`th row of the utility matrix.\n",
    "\n",
    "# Maps user_id: user index\n",
    "u_dict = {uid:i for i, uid in enumerate(df_user_product_prior[\"user_id\"].cat.categories)}\n",
    "\n",
    "# Maps product_index: product id\n",
    "p_dict = dict(enumerate(df_user_product_prior[\"product_id\"].cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing class for factors 50 which returns top recommended items for a user_id\n",
    "svd_recm=TopRecommended(product_factors_50,user_factors_50,product_user_matrix)\n",
    "\n",
    "# Initializing class for factors 100 which returns top recommended items for a user_id\n",
    "svd_recm_100=TopRecommended(product_factors_100,user_factors_100,product_user_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recommend items for a user 1\n",
    "# user_id = 1\n",
    "# print(\"User ID :\",user_id)\n",
    "# # New Recommendations and Old Recommendations\n",
    "# recommendations_all = svd_recm.recommend(u_dict[user_id],N=rec_items)\n",
    "# recommendations_new = svd_recm.recommend_new(u_dict[user_id],N=rec_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Products Bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual products bought by user 34418\n",
      "[9996]\n",
      "\n",
      "\n",
      "New products recommended to user 34418\n",
      "[1696, 2571, 647, 1646, 3882, 1919, 3379, 1928, 2451, 363]\n",
      "Actual products bought by user 17284\n",
      "[9993]\n",
      "\n",
      "\n",
      "New products recommended to user 17284\n",
      "[1919, 272, 1397, 839, 1921, 700, 6769, 5325, 5327, 4701]\n",
      "Actual products bought by user 8132\n",
      "[12286]\n",
      "\n",
      "\n",
      "New products recommended to user 8132\n",
      "[11737, 1919, 1397, 889, 839, 272, 4567, 193, 1862, 1959]\n",
      "Actual products bought by user 36218\n",
      "[194]\n",
      "\n",
      "\n",
      "New products recommended to user 36218\n",
      "[10000, 194, 647, 1649, 378, 794, 791, 1862, 4091, 14897]\n",
      "Actual products bought by user 9127\n",
      "[1804]\n",
      "\n",
      "\n",
      "New products recommended to user 9127\n",
      "[700, 1804, 1919, 601, 5326, 4595, 11798, 1397, 14071, 22964]\n",
      "Actual products bought by user 41538\n",
      "[3831]\n",
      "\n",
      "\n",
      "New products recommended to user 41538\n",
      "[3831, 2529, 1959, 1646, 11305, 4112, 4381, 14828, 4609, 2853]\n",
      "Actual products bought by user 7356\n",
      "[4619]\n",
      "\n",
      "\n",
      "New products recommended to user 7356\n",
      "[1397, 839, 272, 1862, 3831, 700, 6769, 23978, 1917, 1919]\n",
      "Actual products bought by user 7588\n",
      "[79]\n",
      "\n",
      "\n",
      "New products recommended to user 7588\n",
      "[79, 1480, 3365, 1928, 529, 4609, 2339, 2501, 363, 5472]\n"
     ]
    }
   ],
   "source": [
    "users = pd.read_csv(\"../Data/users.csv\")\n",
    "\n",
    "col = ['model','reviewerID','act_products','act_imurl','rec_products','rec_imurl']\n",
    "model='svd'\n",
    "svd_rec_items = pd.DataFrame(columns=col)\n",
    "\n",
    "for r, value in users.iterrows():\n",
    "    act_products = []\n",
    "    act_imurl =[]\n",
    "    rec_products = []\n",
    "    rec_imurl= []\n",
    "    \n",
    "    user_id = value[0]\n",
    "\n",
    "    recommendations_new = svd_recm.recommend_new(u_dict[user_id],N=rec_items)   \n",
    "    row = df_user_products_test.loc[df_user_products_test.user_id == user_id]\n",
    "    actual = list(row[\"products\"])\n",
    "\n",
    "    actual = actual[0][1:-1]\n",
    "    actual = list(np.array([p.strip() for p in actual.strip().split(\",\")]).astype(np.int64))\n",
    "    act_products = []\n",
    "    for pid in actual:\n",
    "#         act_products.extend((df_products.loc[df_products.product_id == pid].product_name).tolist())\n",
    "        act_products.extend((df_products.loc[df_products.product_id == pid].product_id).tolist())\n",
    "        act_imurl.extend((df_products.loc[df_products.product_id == pid].imUrl).tolist())\n",
    "    print(\"Actual products bought by user {}\\n{}\\n\\n\".format(user_id, act_products))\n",
    "\n",
    "    # New Products Recommended \n",
    "    rec_products=[]\n",
    "    for recommend in recommendations_new:\n",
    "#         rec_products.extend((df_products.loc[df_products.product_id == p_dict[recommend[0]]].product_name).tolist())\n",
    "        rec_products.extend((df_products.loc[df_products.product_id == p_dict[recommend[0]]].product_id).tolist())\n",
    "        rec_imurl.extend((df_products.loc[df_products.product_id == p_dict[recommend[0]]].imUrl).tolist())\n",
    "    print(\"New products recommended to user {}\\n{}\".format(user_id, rec_products))\n",
    "\n",
    "\n",
    "    svd_rec_items.loc[len(svd_rec_items)] = [model,user_id,act_products,act_imurl,rec_products,rec_imurl]\n",
    "\n",
    "    svd_rec_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_rec_items.to_csv('../data/svd_rec_items.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Actual\n",
    "# row = df_user_products_test.loc[df_user_products_test.user_id == user_id]\n",
    "# actual = list(row[\"products\"])\n",
    "\n",
    "# actual = actual[0][1:-1]\n",
    "# actual = list(np.array([p.strip() for p in actual.strip().split(\",\")]).astype(np.int64))\n",
    "# act_products = []\n",
    "# for pid in actual:\n",
    "#     act_products.extend((df_products.loc[df_products.product_id == pid].product_name).tolist())\n",
    "# print(\"Actual products bought by user {}\\n{}\\n\\n\".format(user_id, act_products))\n",
    "\n",
    "# # All Products Recommended \n",
    "# all_recm_products=[]\n",
    "# for recommend in recommendations_all:\n",
    "#     all_recm_products.extend((df_products.loc[df_products.product_id == p_dict[recommend[0]]].product_name).tolist())\n",
    "# print(\"All products recommended to user {}\\n{}\\n\\n\".format(user_id, all_recm_products))\n",
    "\n",
    "\n",
    "# # New Products Recommended \n",
    "# new_recm_products=[]\n",
    "# for recommend in recommendations_new:\n",
    "#     new_recm_products.extend((df_products.loc[df_products.product_id == p_dict[recommend[0]]].product_name).tolist())\n",
    "# print(\"New products recommended to user {}\\n{}\".format(user_id, new_recm_products))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def get_k_popular(k, df_order_products_prior):\n",
    "    popular_products = list(df_order_products_prior[\"product_id\"].value_counts().head(k).index)\n",
    "    return popular_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79, 5326, 889, 193, 601, 1010, 848, 761, 1919, 922]\n"
     ]
    }
   ],
   "source": [
    "# Transpose of the product_user utility matrix\n",
    "user_product_matrix = product_user_matrix.T.tocsr()\n",
    "\n",
    "# Number of recommendations to make for every user\n",
    "N_REC = rec_items\n",
    "\n",
    "# Get the `N_REC` most popular products\n",
    "popular_products = get_k_popular(N_REC, df_order_products_prior)\n",
    "print(popular_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_score(actual, pred):\n",
    "    \"\"\"\n",
    "    Given two lists representing actual and predicted values\n",
    "    Returns the recall of the prediction\n",
    "    \"\"\"\n",
    "    if len(actual) == 0:\n",
    "        return 0\n",
    "    actual, pred = set(actual), set(pred)\n",
    "    return len(actual.intersection(pred)) / len(actual)\n",
    "\n",
    "\n",
    "def new_products(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the list of new products purchased\n",
    "    \"\"\"\n",
    "    actual = row[\"products\"][1:-1]  # Products purchased currently \n",
    "    actual = set([int(p.strip()) for p in actual.strip().split(\",\")])\n",
    "    liked = set([p_dict[i] for i in user_product_matrix[u_dict[row[\"user_id\"]]].indices])  # User's purchase history\n",
    "    return actual - liked  # Return only new products purchased\n",
    "\n",
    "\n",
    "def popular_recommend(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the recall score when popular products are recommended\n",
    "    \"\"\"\n",
    "    actual = new_products(row)\n",
    "    return recall_score(actual, popular_products)\n",
    "\n",
    "             \n",
    "def svd_recommend_50_new(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the recall score when our model recommends new products\n",
    "    \"\"\"    \n",
    "    actual = new_products(row)\n",
    "    recommended = svd_recm.recommend_new(u_dict[row[\"user_id\"]], N=N_REC)\n",
    "    recommended = [p_dict[r[0]] for r in recommended]\n",
    "    return recall_score(actual, recommended)\n",
    "\n",
    "def svd_recommend_100_new(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the recall score when our model recommends new products\n",
    "    \"\"\"    \n",
    "    actual = new_products(row)\n",
    "    recommended = svd_recm_100.recommend_new(u_dict[row[\"user_id\"]], N=N_REC)\n",
    "    recommended = [p_dict[r[0]] for r in recommended]\n",
    "    return recall_score(actual, recommended)\n",
    "\n",
    "\n",
    "             \n",
    "def build_eval_df(df_user_products_test, filepath=None, subset=None):\n",
    "    \"\"\"\n",
    "    Builds a dataframe of recall values of the baseline and our model for all the users\n",
    "    in the test data, and saves its to disk at `filepath`\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"Building dataframe with recall values ...\")\n",
    "    \n",
    "    df_eval = df_user_products_test.copy()\n",
    "    if subset:\n",
    "        df_eval = df_eval.sample(n=int(len(df_eval) * subset), random_state=7)\n",
    "    df_eval[\"popular_score\"] = df_eval.apply(popular_recommend, axis=1)\n",
    "    df_eval[\"svd_new_score_50\"] = df_eval.apply(svd_recommend_50_new, axis=1)\n",
    "    df_eval[\"svd_new_score_100\"] = df_eval.apply(svd_recommend_100_new, axis=1)\n",
    "    df_eval.to_csv(filepath, index=False)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataframe with recall values ...\n",
      "Completed in 124.48s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the dataframe with recall values of the baseline and the model\n",
    "REBUILD_EVAL_DF = True\n",
    "subset = 0.2  # Evaluate on `subset x 100`% of the test dataset\n",
    "eval_path = \"../data/eval/eval_discovery_svd_{}_{}.csv\".format(subset if subset is not None else \"full\", N_REC)\n",
    "if REBUILD_EVAL_DF or not Path(eval_path).exists():\n",
    "    build_eval_df(df_user_products_test, filepath=eval_path, subset=subset)\n",
    "df_eval = pd.read_csv(eval_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD 100 Factor Model: 1.31%\n",
      "SVD 50 Factor Model: 1.08%\n",
      "Baseline: 0.66%\n"
     ]
    }
   ],
   "source": [
    "# Mean recall scores\n",
    "model_50_mean_recall,model_100_mean_recall, baseline_mean_recall = \\\n",
    "np.mean(df_eval[\"svd_new_score_50\"]),np.mean(df_eval[\"svd_new_score_100\"]), np.mean(df_eval[\"popular_score\"])\n",
    "print(\"SVD 100 Factor Model: {:.2f}%\".format(model_100_mean_recall * 100))\n",
    "print(\"SVD 50 Factor Model: {:.2f}%\".format(model_50_mean_recall * 100))\n",
    "print(\"Baseline: {:.2f}%\".format(baseline_mean_recall * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
