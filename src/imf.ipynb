{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System\n",
    "### Matrix Factorization for implicit feedback data using Alternating Least Squares\n",
    "\n",
    "The matrix factorization performed in this notebook is based on the this [paper](http://yifanhu.net/PUB/cf.pdf) by Yehuda Koren et. al which explores an alternative way to represent utility matrices with implicit feedback. We are using the library [`implicit`](https://github.com/benfred/implicit) which implements the outlined algorithm.\n",
    "\n",
    "*Note:* Datafiles are built from scratch in this notebook only if they don't exist on disk. However, to force rebuild any datafile, there will be a `REBUILD_*` constant in the respective cell that should be set to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order datasets\n",
    "df_order_products_prior = pd.read_csv(\"../data/order_products__prior.csv\")\n",
    "df_order_products_train = pd.read_csv(\"../data/order_products__train.csv\")\n",
    "df_orders = pd.read_csv(\"../data/orders.csv\") \n",
    "\n",
    "# Products\n",
    "df_products = pd.read_csv(\"../data/products.csv\")\n",
    "# Merge prior orders and products\n",
    "df_merged_order_products_prior = pd.merge(df_order_products_prior, df_products, on=\"product_id\", how=\"left\")\n",
    "\n",
    "rec_items = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test data ...\n",
      "Completed in 2.54s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>[46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>[75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>[56]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>[81]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>[83]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>[101]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>[102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[327]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>[35263]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>[124]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>[134]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21</td>\n",
       "      <td>[139]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23</td>\n",
       "      <td>[147]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id products\n",
       "0         1      [1]\n",
       "1         3      [9]\n",
       "2         5     [20]\n",
       "3         6     [26]\n",
       "4         7     [35]\n",
       "5         8     [46]\n",
       "6         8     [75]\n",
       "7         8     [50]\n",
       "8         8     [41]\n",
       "9         8     [56]\n",
       "10        9     [81]\n",
       "11       10     [83]\n",
       "12       12    [101]\n",
       "13       12    [102]\n",
       "14       14    [327]\n",
       "15       16  [35263]\n",
       "16       18    [124]\n",
       "17       20    [134]\n",
       "18       21    [139]\n",
       "19       23    [147]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_test_data(filepath, df_orders, df_order_products_train):\n",
    "    \"\"\"\n",
    "    Generates the test dataset and saves it to disk at the given path\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Creating test data ...\")\n",
    "\n",
    "    # Read train csv\n",
    "    df_order_user_current = df_orders.loc[(df_orders.eval_set == \"train\")].reset_index()\n",
    "    df_order_user_current = df_order_user_current[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    # Sanity check #1: `current_order_user_df` and `df_order_products_train` should have the same number of \n",
    "    # unique order ids\n",
    "    assert len(df_order_user_current[\"order_id\"].unique()) == len(df_order_products_train[\"order_id\"].unique())\n",
    "\n",
    "    # Convert train dataframe to a similar format\n",
    "    df_order_products_test = df_order_products_train[[\"order_id\", \"product_id\"]]\n",
    "    df_order_products_test = df_order_products_test.groupby(\"order_id\")[\"product_id\"].apply(list).reset_index().rename(columns={\"product_id\": \"products\"})\n",
    "\n",
    "    # Sanity check #2: `df_order_products_test` and `df_order_user_current` should have the same number of \n",
    "    # records before attempting to merge them\n",
    "    assert df_order_products_test.size == df_order_user_current.size\n",
    "\n",
    "    # Merge on order id\n",
    "    df_user_products_test = pd.merge(df_order_user_current, df_order_products_test, on=\"order_id\")\n",
    "    df_user_products_test = df_user_products_test[[\"user_id\", \"products\"]]\n",
    "\n",
    "    # Write to disk\n",
    "    df_user_products_test.to_csv(filepath, index_label=False, index=False)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "\n",
    "# Generate test data if it doesn't exist already\n",
    "REBUILD_TEST_DATA = True\n",
    "test_data_path = \"../data/user_products__test.csv\"\n",
    "if REBUILD_TEST_DATA or not Path(test_data_path).is_file():\n",
    "    make_test_data(test_data_path, df_orders, df_order_products_train)\n",
    "\n",
    "df_user_products_test = pd.read_csv(test_data_path)\n",
    "df_user_products_test.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating prior user-product data frame ...\n",
      "Completed in 1.66s\n"
     ]
    }
   ],
   "source": [
    "def get_user_product_prior_df(filepath, df_orders, df_order_products_prior):\n",
    "    \"\"\"\n",
    "    Generates a dataframe of users and their prior products purchases, and writes it to disk at the given path\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Creating prior user-product data frame ...\")\n",
    "    \n",
    "    # Consider ony \"prior\" orders and remove all columns except `user_id` from `df_orders`\n",
    "    df_order_user_prior = df_orders.loc[df_orders.eval_set == \"prior\"]\n",
    "    df_order_user_prior = df_order_user_prior[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    # Remove all columns except order_id and user_id from df_orders and \n",
    "    # merge the above on `order_id` and remove `order_id`\n",
    "    df_merged = pd.merge(df_order_user_prior, df_order_products_prior[[\"order_id\", \"product_id\"]], on=\"order_id\")\n",
    "    df_user_product_prior = df_merged[[\"user_id\", \"product_id\"]]\n",
    "    df_user_product_prior = df_user_product_prior.groupby([\"user_id\", \"product_id\"]).size().reset_index().rename(columns={0:\"quantity\"})\n",
    "    \n",
    "    # Write to disk\n",
    "    df_user_product_prior.to_csv(filepath, index_label=False, index=False)\n",
    "\n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "\n",
    "# Build dataframe of users and their prior product purchases.\n",
    "# This is needed for building the utility matrix\n",
    "REBUILD_MATRIX_DF = True\n",
    "matrix_df_path = \"../data/user_products__prior.csv\"\n",
    "if REBUILD_MATRIX_DF or not Path(matrix_df_path).is_file():\n",
    "    get_user_product_prior_df(matrix_df_path, df_orders, df_order_products_prior)\n",
    "\n",
    "df_user_product_prior = pd.read_csv(matrix_df_path)\n",
    "df_user_product_prior[\"user_id\"] = df_user_product_prior[\"user_id\"].astype(\"category\")\n",
    "df_user_product_prior[\"product_id\"] = df_user_product_prior[\"product_id\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating product user matrix ...\n",
      "Completed in 0.26s\n"
     ]
    }
   ],
   "source": [
    "def build_product_user_matrix(matrix_path, df_user_product_prior):\n",
    "    \"\"\"\n",
    "    Generates a utility matrix representing purchase history of users, and writes it to disk.\n",
    "    Rows and Columns represent products and users respectively.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"Creating product user matrix ...\")\n",
    "\n",
    "    product_user_matrix = sparse.coo_matrix((df_user_product_prior[\"quantity\"],\n",
    "                                            (df_user_product_prior[\"product_id\"].cat.codes.copy(),\n",
    "                                             df_user_product_prior[\"user_id\"].cat.codes.copy())))    \n",
    "    sparse.save_npz(matrix_path, product_user_matrix)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "\n",
    "# Get the `product x user` utility matrix\n",
    "REBUILD_MATRIX = True\n",
    "matrix_path = \"../data/product_user_matrix.npz\"\n",
    "if REBUILD_MATRIX or not Path(matrix_path).is_file():\n",
    "    build_product_user_matrix(matrix_path, df_user_product_prior)\n",
    "\n",
    "product_user_matrix = sparse.load_npz(matrix_path).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.99555128671498"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How sparse is the utility matrix?\n",
    "def sparsity(matrix):\n",
    "    \"\"\"\n",
    "    Given a matrix, returns its sparsity\n",
    "    \"\"\"\n",
    "    total_size = matrix.shape[0] * matrix.shape[1]\n",
    "    actual_size = matrix.size\n",
    "    sparsity = (1 - (actual_size / total_size)) * 100\n",
    "    return(sparsity)\n",
    "\n",
    "sparsity(product_user_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit Matrix Factorization using ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building IMF model with alpha: 15 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 15.0/15 [00:08<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 9.32s\n"
     ]
    }
   ],
   "source": [
    "def confidence_matrix(prod_user_matrix, alpha):\n",
    "    \"\"\"\n",
    "    Given a utility matrix,\n",
    "    Returns the given matrix converted to a confidence matrix\n",
    "    For more details, look at http://yifanhu.net/PUB/cf.pdf\n",
    "    \"\"\"\n",
    "    return (prod_user_matrix * alpha).astype(\"double\")\n",
    "    \n",
    "\n",
    "def build_imf(prod_user_matrix, **kwargs):\n",
    "    \"\"\"\n",
    "    Given the utility matrix and model parameters,\n",
    "    Builds models and writes it to disk at \n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Build model\n",
    "    print(\"Building IMF model with alpha: {} ...\".format(kwargs[\"alpha\"]))\n",
    "    model = AlternatingLeastSquares()\n",
    "    model.approximate_similar_items = False\n",
    "    \n",
    "    model.fit(confidence_matrix(prod_user_matrix, kwargs[\"alpha\"]))\n",
    "\n",
    "    # Save model to disk\n",
    "    with open(kwargs[\"path\"], \"wb+\") as f:\n",
    "        pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "    \n",
    "# Specify model params and build it\n",
    "## Alpha's in the range [10, 50] with a step size of 5 were tried. alpha = 15 was found to have the best overall \n",
    "## recall value. \n",
    "model_params = {\"alpha\": 15} \n",
    "model_params[\"path\"] = \"../models/imf/{}.imf\".format(model_params[\"alpha\"])\n",
    "\n",
    "REBUILD_MODEL = True\n",
    "if REBUILD_MODEL or not Path(model_params[\"path\"]).exists():\n",
    "    build_imf(product_user_matrix, **model_params)\n",
    "with open(model_params[\"path\"], \"rb\") as f:\n",
    "    imf_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the utility matrix is 0-indexed, the below dict is required to convert between `ids` and `indices`.\n",
    "# For example, `product_id` 1 in the dataset is represented by the `0`th row of the utility matrix.\n",
    "\n",
    "# Maps user_id: user index\n",
    "u_dict = {uid:i for i, uid in enumerate(df_user_product_prior[\"user_id\"].cat.categories)}\n",
    "\n",
    "# Maps product_index: product id\n",
    "p_dict = dict(enumerate(df_user_product_prior[\"product_id\"].cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual products bought by user 34418\n",
      "[9996]\n",
      "\n",
      "Recommendations for user 34418\n",
      "[3040, 2396, 1645, 1184, 8238, 2571, 10569, 393, 4716, 13289]\n",
      "Actual products bought by user 17284\n",
      "[9993]\n",
      "\n",
      "Recommendations for user 17284\n",
      "[1919, 5325, 1921, 5327, 17879, 9993, 1665, 13805, 16039, 2449]\n",
      "Actual products bought by user 8132\n",
      "[12286]\n",
      "\n",
      "Recommendations for user 8132\n",
      "[889, 12286, 1696, 5326, 170, 834, 5033, 2789, 1375, 1551]\n",
      "Actual products bought by user 36218\n",
      "[194]\n",
      "\n",
      "Recommendations for user 36218\n",
      "[194, 647, 12397, 10000, 5807, 5845, 2501, 1686, 788, 1849]\n",
      "Actual products bought by user 9127\n",
      "[1804]\n",
      "\n",
      "Recommendations for user 9127\n",
      "[1664, 4091, 1804, 2410, 5629, 117, 1580, 1907, 1663, 116]\n",
      "Actual products bought by user 41538\n",
      "[3831]\n",
      "\n",
      "Recommendations for user 41538\n",
      "[2529, 1645, 16106, 2853, 536, 1658, 1184, 1944, 2474, 4716]\n",
      "Actual products bought by user 7356\n",
      "[4619]\n",
      "\n",
      "Recommendations for user 7356\n",
      "[7575, 4619, 23978, 3691, 3897, 5326, 1397, 8932, 170, 1804]\n",
      "Actual products bought by user 7588\n",
      "[79]\n",
      "\n",
      "Recommendations for user 7588\n",
      "[79, 1849, 4609, 1224, 4121, 848, 25743, 6353, 5472, 852]\n"
     ]
    }
   ],
   "source": [
    "users = pd.read_csv(\"../Data/users.csv\")\n",
    "\n",
    "col = ['model','reviewerID','act_products','act_imurl','rec_products','rec_imurl']\n",
    "model='imf'\n",
    "imf_rec_items = pd.DataFrame(columns=col)\n",
    "\n",
    "for rr, value in users.iterrows():\n",
    "    act_products = []\n",
    "    act_imurl =[]\n",
    "    rec_products = []\n",
    "    rec_imurl= []\n",
    "    \n",
    "    user_id = value[0]\n",
    "    \n",
    "    recommendations = imf_model.recommend(u_dict[user_id], product_user_matrix.T.tocsr(), N = rec_items)\n",
    "    row = df_user_products_test.loc[df_user_products_test.user_id == user_id]\n",
    "    actual = list(row[\"products\"])\n",
    "    actual = actual[0][1:-1]\n",
    "    actual = list(np.array([p.strip() for p in actual.strip().split(\",\")]).astype(np.int64))\n",
    "\n",
    "    for pid in actual:\n",
    "#         act_products.extend((df_products.loc[df_products.product_id == pid].product_name).tolist())\n",
    "        act_products.extend((df_products.loc[df_products.product_id == pid].product_id).tolist())\n",
    "        act_imurl.extend((df_products.loc[df_products.product_id == pid].imUrl).tolist())\n",
    "    print(\"Actual products bought by user {}\\n{}\".format(user_id, act_products))\n",
    "\n",
    "    # Recommended\n",
    "    r = [p_dict[r[0]] for r in recommendations] # Takes the product_cat_code and maps to product_id\n",
    "\n",
    "    for pid in r:\n",
    "#         rec_products.extend((df_products.loc[df_products.product_id == pid].product_name).tolist())\n",
    "        rec_products.extend((df_products.loc[df_products.product_id == pid].product_id).tolist())\n",
    "        rec_imurl.extend((df_products.loc[df_products.product_id == pid].imUrl).tolist())\n",
    "    print(\"\\nRecommendations for user {}\\n{}\".format(user_id, rec_products))\n",
    "    \n",
    "    imf_rec_items.loc[len(imf_rec_items)] = [model,user_id,act_products,act_imurl,rec_products,rec_imurl]\n",
    "    imf_rec_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imf_rec_items.to_csv('../data/imf_rec_items.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recommend items for a user 1\n",
    "# user_id = 1\n",
    "# recommendations = imf_model.recommend(u_dict[user_id], product_user_matrix.T.tocsr(), N = rec_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Actual \n",
    "# row = df_user_products_test.loc[df_user_products_test.user_id == user_id]\n",
    "# actual = list(row[\"products\"])\n",
    "# actual = actual[0][1:-1]\n",
    "# actual = list(np.array([p.strip() for p in actual.strip().split(\",\")]).astype(np.int64))\n",
    "# act_products = []\n",
    "# for pid in actual:\n",
    "#     act_products.extend((df_products.loc[df_products.product_id == pid].product_name).tolist())\n",
    "# print(\"Actual products bought by user {}\\n{}\".format(user_id, act_products))\n",
    "\n",
    "# # Recommended\n",
    "# r = [p_dict[r[0]] for r in recommendations] # Takes the product_cat_code and maps to product_id\n",
    "# rec_products = []\n",
    "# for pid in r:\n",
    "#     rec_products.extend((df_products.loc[df_products.product_id == pid].product_name).tolist())\n",
    "# print(\"\\nRecommendations for user {}\\n{}\".format(user_id, rec_products))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our recommender is discovery based and hence recommends products that the user has never purchased before. Hence, for evaluation, we are removing products purchased before from his current purchase represented by `actual`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using `Recall`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_popular(k, df_merged_order_products_prior):\n",
    "    \"\"\"\n",
    "    Returns the `k` most popular products based on purchase count in the dataset\n",
    "    \"\"\"\n",
    "    popular_products = list(df_merged_order_products_prior[\"product_id\"].value_counts().head(k).index)\n",
    "    return popular_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose of the product_user utility matrix\n",
    "user_product_matrix = product_user_matrix.T.tocsr()\n",
    "\n",
    "# Number of recommendations to make for every user\n",
    "N_REC = rec_items\n",
    "\n",
    "# Get the `N_REC` most popular products\n",
    "popular_products = get_k_popular(N_REC, df_merged_order_products_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataframe with recall values ...\n",
      "Completed in 43.10s\n"
     ]
    }
   ],
   "source": [
    "def recall_score(actual, pred):\n",
    "    \"\"\"\n",
    "    Given two lists representing actual and predicted values\n",
    "    Returns the recall of the prediction\n",
    "    \"\"\"\n",
    "    if len(actual) == 0:\n",
    "        return 0\n",
    "    actual, pred = set(actual), set(pred)\n",
    "    return len(actual.intersection(pred)) / len(actual)\n",
    "\n",
    "\n",
    "def new_products(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the list of new products purchased\n",
    "    \"\"\"\n",
    "    actual = row[\"products\"][1:-1]  # Products purchased currently \n",
    "    actual = set([int(p.strip()) for p in actual.strip().split(\",\")])\n",
    "    liked = set([p_dict[i] for i in user_product_matrix[u_dict[row[\"user_id\"]]].indices])  # User's purchase history\n",
    "    return actual - liked  # Return only new products purchased\n",
    "\n",
    "\n",
    "def popular_recommend(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the recall score when popular products are recommended\n",
    "    \"\"\"\n",
    "    actual = new_products(row)\n",
    "    return recall_score(actual, popular_products)\n",
    "\n",
    "             \n",
    "def imf_recommend(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the recall score when our model recommends products\n",
    "    \"\"\"\n",
    "    actual = new_products(row)\n",
    "    recommended = imf_model.recommend(u_dict[row[\"user_id\"]], user_product_matrix, N=N_REC)\n",
    "    recommended = [p_dict[r[0]] for r in recommended]\n",
    "    return recall_score(actual, recommended)\n",
    "\n",
    "             \n",
    "def build_eval_df(df_user_products_test, filepath=None, subset=None):\n",
    "    \"\"\"\n",
    "    Builds a dataframe of recall values of the baseline and our model for all the users\n",
    "    in the test data, and saves its to disk at `filepath`\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"Building dataframe with recall values ...\")\n",
    "    \n",
    "    df_eval = df_user_products_test.copy()\n",
    "    if subset:\n",
    "        df_eval = df_eval.sample(n=int(len(df_eval) * subset), random_state=7)\n",
    "    df_eval[\"popular_score\"] = df_eval.apply(popular_recommend, axis=1)\n",
    "    df_eval[\"imf_score\"] = df_eval.apply(imf_recommend, axis=1)\n",
    "    \n",
    "    df_eval.to_csv(filepath, index=False)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))    \n",
    "\n",
    "\n",
    "# Get the dataframe with recall values of the baseline and the model\n",
    "REBUILD_EVAL_DF = True\n",
    "subset = 0.2  # Evaluate on `subset x 100`% of the test dataset\n",
    "eval_path = \"../data/eval/eval_discovery_{}_{}.csv\".format(subset if subset is not None else \"full\", N_REC)\n",
    "if REBUILD_EVAL_DF or not Path(eval_path).exists():\n",
    "    build_eval_df(df_user_products_test, filepath=eval_path, subset=subset)\n",
    "df_eval = pd.read_csv(eval_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 2.05%\n",
      "Baseline: 0.66%\n"
     ]
    }
   ],
   "source": [
    "# Mean recall scores\n",
    "model_mean_recall, baseline_mean_recall = np.mean(df_eval[\"imf_score\"]), np.mean(df_eval[\"popular_score\"])\n",
    "print(\"Model: {:.2f}%\".format(model_mean_recall * 100))\n",
    "print(\"Baseline: {:.2f}%\".format(baseline_mean_recall * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendations through matrix factorization are almost a factor of 2 times better than the baseline model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
